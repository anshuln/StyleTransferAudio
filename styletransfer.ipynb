{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# !pip install --upgrade tensorflow\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 1 model encoder\n# 1.1 models 2 encoders\n# 2 separate decoders, one for each genre\n# discriminator model, latent space\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D,ReLU,BatchNormalization,Conv2DTranspose,MaxPool2D,Dense,Flatten,Layer\nprint(tf.__version__)\n\ndisclosswt = 0.0001\n# tf.reset_default_graph()\n# tf.clear_all_variables()\n\nclass MaxPool2D(Layer):\n\n    def __init__(\n            self,\n            ksize=(2, 2),\n            strides=(2, 2),\n            padding='same',\n            **kwargs):\n        super(MaxPool2D, self).__init__(autocast=False)\n        self.padding = padding\n        self.pool_size = ksize\n        self.strides = strides\n\n    def call(self, inputs, **kwargs):\n        padding = self.padding\n        pool_size = self.pool_size\n        strides = self.strides\n        ksize = [1, pool_size[0], pool_size[1], 1]\n        padding = padding.upper()\n        strides = [1, strides[0], strides[1], 1]\n        output, argmax = tf.nn.max_pool_with_argmax(\n                inputs,\n                ksize=ksize,\n                strides=strides,\n                padding=padding)\n        argmax = tf.cast(argmax, tf.float64)\n        return [output, argmax]\n\n    def compute_output_shape(self, input_shape):\n        ratio = (1, 2, 2, 1)\n        output_shape = [\n                dim//ratio[idx]\n                if dim is not None else None\n                for idx, dim in enumerate(input_shape)]\n        output_shape = tuple(output_shape)\n        return [output_shape, output_shape]\n\n    def compute_mask(self, inputs, mask=None):\n        return 2 * [None]\n\n\nclass MaxUnpool2D(Layer):\n    def __init__(self, ksize=(2, 2), **kwargs):\n        super(MaxUnpool2D, self).__init__(autocast=False,**kwargs)\n        self.size = ksize\n\n    def call(self, inputs, output_shape=None):\n        updates, mask = inputs[0], inputs[1]\n        mask = tf.cast(mask, 'int32')\n        input_shape = tf.shape(updates, out_type='int32')\n        #  calculation new shape\n        if output_shape is None:\n            output_shape = (\n                    input_shape[0],\n                    input_shape[1]*self.size[0],\n                    input_shape[2]*self.size[1],\n                    input_shape[3])\n        self.output_shape1 = output_shape\n\n        # calculation indices for batch, height, width and feature maps\n        one_like_mask = tf.ones_like(mask, dtype='int32')\n        batch_shape = tf.concat(\n                [[input_shape[0]], [1], [1], [1]],\n                axis=0)\n        batch_range = tf.reshape(\n                tf.range(output_shape[0], dtype='int32'),\n                shape=batch_shape)\n        # print(\"SHAPE______\",output_shape[3])\n        b = one_like_mask * batch_range\n        y = mask // (output_shape[2] * output_shape[3])\n        x = (mask // output_shape[3]) % output_shape[2]\n        feature_range = tf.range(output_shape[3], dtype='int32')\n        f = one_like_mask * feature_range\n\n        # transpose indices & reshape update values to one dimension\n        updates_size = tf.size(updates)\n        indices = tf.transpose(tf.reshape(\n            tf.stack([b, y, x, f]),\n            [4, updates_size]))\n        values = tf.reshape(updates, [updates_size])\n        ret = tf.scatter_nd(indices, values, output_shape)\n        return ret\n\n    def compute_output_shape(self, input_shape):\n        mask_shape = input_shape[1]\n        return (\n                mask_shape[0],\n                mask_shape[1]*self.size[0],\n                mask_shape[2]*self.size[1],\n                mask_shape[3]\n                )\nclass segnet(tf.keras.Sequential):\n    def __init__(self):\n        super(segnet,self).__init__()\n    def conv_layer(self, channel):\n        conv_block = tf.keras.Sequential(\n            [Conv2D(filters=channel, kernel_size=3, padding=\"same\",kernel_initializer='glorot_normal'),\n            BatchNormalization(axis=-1),\n            ReLU()]\n        )\n        return conv_block\n\nclass encoder(segnet):\n    def __init__(self,channels=3):\n        super(encoder,self).__init__()\n        filter = [64, 128, 256, 512, 512]\n        self.conv_block_enc = []\n        self.conv_block_enc.append(Sequential([self.conv_layer(filter[0]),self.conv_layer(filter[0])]))\n        for i in range(4):  #TODO Refactor for better model making\n            if i == 0:\n                self.conv_block_enc.append(Sequential([self.conv_layer(filter[i + 1]),\n                                                    self.conv_layer(filter[i + 1])]))\n            else:\n                self.conv_block_enc.append(Sequential([self.conv_layer(filter[i + 1]),\n                                                    self.conv_layer(filter[i + 1]),\n                                                    self.conv_layer(filter[i + 1])]))\n        self.down_sampling = MaxPool2D(ksize=(2,2),padding='same')\n    def call(self,x):\n        x1 = x\n        indices = []\n        for i in range(5):\n            x1 = self.conv_block_enc[i](x1)\n            x1,index = self.down_sampling.call(x1)\n            indices.append(index)\n            #print(\"Encode\",x1.shape,indices[-1].shape)\n        self.encout = x1\n        self.indices = indices\n\nclass decoder(segnet):\n    def __init__(self,channels=3):\n        super(decoder,self).__init__()\n        filter = [64, 128, 256, 512, 512]\n        self.conv_block_dec = []\n#       self.conv_block_dec = Sequential()\n        for i in range(1,4):\n            self.conv_block_dec.append(Sequential([self.conv_layer(filter[-i]),\n                                                  self.conv_layer(filter[-i]),\n                                                  self.conv_layer(filter[-(i+1)])]))\n\n        self.conv_block_dec.append(Sequential([self.conv_layer(filter[1]),\n                                                  self.conv_layer(filter[0])]))\n        self.conv_block_dec.append(Sequential([self.conv_layer(filter[0]),\n                                                  tf.keras.Sequential(\n            [Conv2D(filters=1, kernel_size=3, padding=\"same\",kernel_initializer='glorot_normal'),\n             BatchNormalization(axis=-1),\n             ReLU()]\n        )]))    #Getting best results when sigmoid, batch_norm, relu\n        \n        self.up_sampling = MaxUnpool2D(ksize=(2,2))\n    def forward(self,X,indices):\n        indices = indices[::-1]\n        for idx,layer in enumerate(self.conv_block_dec):\n            #print(X.shape,indices[idx].shape)\n            # print(idx,X.shape,self.max_indices[idx].shape)\n            X = self.up_sampling.call([X,indices[idx]])\n            #print(idx,X.shape,indices[idx].shape)\n            X = layer(X) \n        return X\n# class unet(tf.keras.Sequential):\n#     def __init__(self):\n#         super(unet,self).__init__()\n    \n#     def contracting_block(self,in_channels,out_channels,kernel_size=(3,3)):\n#         layers = [Conv2D(filters=out_channels,kernel_size=kernel_size,padding=\"same\",activation=\"relu\"),\n#                     BatchNormalization(axis=-1),\n#                     Conv2D(filters=out_channels,kernel_size=kernel_size,padding=\"same\",activation=\"relu\"),\n#                     BatchNormalization(axis=-1)]\n#         return tf.keras.Sequential(layers)\n    \n#     def expansive_block(self,in_channels,mid_channels,out_channels,kernel_size=(3,3)):\n#         layers = [Conv2D(filters=mid_channels,kernel_size=kernel_size,padding=\"same\",activation=\"relu\"),\n#                     BatchNormalization(axis=-1),\n#                     Conv2D(filters=mid_channels,kernel_size=kernel_size,padding=\"same\",activation=\"relu\"),\n#                     BatchNormalization(axis=-1),\n#                     Conv2DTranspose(filters=out_channels,kernel_size=kernel_size,strides=2,output_padding=1,padding=\"same\")\n#                  ]\n#         return tf.keras.Sequential(layers)\n    \n#     def final_block(self,in_channels,mid_channels,out_channels,kernel_size=3):\n#         layers = [Conv2D(filters=mid_channels,kernel_size=kernel_size,padding=\"same\",activation=\"relu\"),\n#                     BatchNormalization(axis=-1),\n#                     Conv2D(filters=mid_channels,kernel_size=kernel_size,padding=\"same\",activation=\"relu\"),\n#                     BatchNormalization(axis=-1),\n#                     Conv2D(filters=out_channels,kernel_size=kernel_size,padding=\"same\",activation=\"relu\"),\n#                     #BatchNormalization(axis=-1)\n#                  ]\n#         return tf.keras.Sequential(layers)\n\n    \n# class encoder(unet):\n#     def __init__(self,imsize):\n#         super(encoder,self).__init__()\n#         self.conv_encode1 = self.contracting_block(in_channels=1, out_channels=64)\n#         self.conv_maxpool1 = MaxPool2D(pool_size=2)\n#         self.conv_encode2 = self.contracting_block(64, 128)\n#         self.conv_maxpool2 = MaxPool2D(pool_size=2)\n#         self.conv_encode3 = self.contracting_block(128, 256)\n#         self.conv_maxpool3 = MaxPool2D(pool_size=3)\n#         # Bottleneck\n#         self.bottleneck1 = tf.keras.Sequential(\n#                             [\n#                             Conv2D(kernel_size=(3,3), filters=512,activation=\"relu\",padding=\"same\"),\n#                             BatchNormalization(axis=-1),\n#                             Conv2D(kernel_size=(3,3), filters=512,activation=\"relu\",padding=\"same\"),\n#                             BatchNormalization(axis=-1)])\n#         self.bottleneck2 = tf.keras.Sequential([Conv2DTranspose(filters=256,kernel_size=(2,2),strides=3,output_padding=1,padding=\"valid\",activation=\"relu\")])\n        \n# #     @tf.function\n#     def call(self,x):\n#         self.encode_block1 = self.conv_encode1(x)\n#         encode_pool1 = self.conv_maxpool1(self.encode_block1)\n#         self.encode_block2 = self.conv_encode2(encode_pool1)\n#         encode_pool2 = self.conv_maxpool2(self.encode_block2)\n#         self.encode_block3 = self.conv_encode3(encode_pool2)\n#         encode_pool3 = self.conv_maxpool3(self.encode_block3)\n#         self.discin = self.bottleneck1(encode_pool3)\n#         self.encout = self.bottleneck2(self.discin)\n        \n# class decoder(unet):\n#     def crop_and_concat(self, upsampled, bypass, crop=False):\n#         if crop:\n#             c = (tf.shape(bypass)[2] - upsampled.shape[2]) // 2\n#             bypass = tf.keras.layers.Cropping2D(cropping=(c,c))(bypass)\n#         return tf.concat((upsampled, bypass),axis=-1)\n    \n#     def __init__(self,imsize,out_channel=1):\n#         super(decoder,self).__init__()\n# #         self.con\n# #         self.convtr = Conv2DTranspose(filters=512,kernel_size=(3,3),strides=2,output_padding=1,padding=\"same\")\n#         self.conv_decode3 = self.expansive_block(512, 256, 128)\n#         self.conv_decode2 = self.expansive_block(256, 128, 64)\n#         self.final_layer = self.final_block(128, 64, out_channel)\n    \n# #     @tf.function\n#     def forward(self,bottleneck1,encode_block1,encode_block2,encode_block3):\n#         decode_block3 = bottleneck1\n#         cat_layer2 = self.conv_decode3(decode_block3)\n#         decode_block2 = cat_layer2\n#         cat_layer1 = self.conv_decode2(decode_block2)\n#         decode_block1 = cat_layer1\n#         final_layer = self.final_layer(decode_block1)\n#         return  final_layer\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Model(tf.keras.Sequential):\n    def __init__(self,encoders,decoders):\n#       encoder is a model of type encoder defined above,\n#       decoders is a list of decoders \n        super(Model,self).__init__()\n        self.encoder = encoders\n        self.decoders = decoders\n        self.discriminator = tf.keras.Sequential([Conv2D(kernel_size=(8,8),strides=1,filters=1024,padding='valid'),Flatten(),Dense(1024,activation=\"relu\"),Dense(1024,activation=\"relu\"),Dense(1,activation='linear')])\n        self.TrainableVarsSet = False\n    \n    def setTrainableVars(self):\n        self.genTrainableVariables = self.encoder.trainable_variables+self.decoders[0].trainable_variables+self.decoders[1].trainable_variables\n        self.discTrainableVariables = self.discriminator.trainable_variables\n        self.TrainableVarsSet = True\n#     @tf.function\n    def forwardX2Y(self,X,training=False):\n        # target_index index of target genre\n        self.encoder.call(X)\n        #print(self.encoder.encout.shape)\n        decoded_out = self.decoders[1].forward(self.encoder.encout,self.encoder.indices)\n        if training == True:\n            return decoded_out,self.discriminator(self.encoder.encout)\n        else:\n            return decoded_out\n#     @tf.function\n    def forwardY2X(self,X,training=False):\n        # target_index index of target genre\n        self.encoder.call(X)\n        #print(self.encoder.encout.shape)\n        decoded_out = self.decoders[0].forward(self.encoder.encout,self.encoder.indices)\n        if training == True:\n            return decoded_out,self.discriminator(self.encoder.encout)\n        else:\n            return decoded_out\n#     @tf.function\n    def forwardX2X(self,X,training=False):\n        # target_index index of target genre\n        self.encoder.call(X)\n        decoded_out = self.decoders[0].forward(self.encoder.encout,self.encoder.indices)\n        if training == True:\n            return decoded_out,self.discriminator(self.encoder.encout)\n        else:\n            return decoded_out\n#     @tf.function\n    def forwardY2Y(self,X,training=False):\n        # target_index index of target genre\n        self.encoder.call(X)\n        decoded_out = self.decoders[1].forward(self.encoder.encout,self.encoder.indices)\n        if training == True:\n            return decoded_out,self.discriminator(self.encoder.encout)\n        else:\n            return decoded_out        \n    def build_disc(self,X):\n        #Function to build disciminator initially, please don't call ever again.\n        self.encoder.call(X)\n        #print(self.encoder.encout)\n        self.discriminator(self.encoder.encout)\n        \n    def reconstruction_loss(self,X,Y):\n        # print(X.shape,Y.shape)\n        #Pixel-wise l2 loss\n        # return  tf.math.reduce_sum(tf.math.reduce_sum(tf.math.reduce_sum((X-Y)**2,\n            # axis=-1),axis=-1),axis=-1,keepdims=True)    #see if keepdims is required\n        return tf.math.reduce_mean(tf.math.abs(X-Y))\n\n    def loss_classification(self,X,labels):\n        return (-1*tf.reduce_mean(labels*(tf.math.log(X+1e-5)) + (1-labels)*(tf.math.log(1-X+1e-5))))\n    \n    def loss_disc(self,X,labels):\n        #Wasserstein loss\n        #print((X*(2*labels-1)).shape)\n        return -1*tf.reduce_mean(X*(2*labels-1))*disclosswt\n    \n    @tf.function\n    def train_on_batch(self,X,labels,optimizerGen,optimizerDisc):\n        if self.TrainableVarsSet == False:\n            self.setTrainableVars()\n        n,h,w,c = X.shape\n        X1 = tf.slice(X,[0,0,0,0],[n//2,h,w,c])\n        X2 = tf.slice(X,[n//2,0,0,0],[n//2,h,w,c])\n        with tf.GradientTape(persistent=True) as tape:\n            transformedX2Y,disc1 = self.forwardX2Y(X1,training=True)\n            transformedY2X,disc2 = self.forwardY2X(X2,training=True)\n            \n            loss_disc = self.loss_disc(tf.concat([disc1,disc2],axis=0),labels)\n            discfeats = tf.concat([disc1,disc2],axis=0)\n            #print(discfeats)\n            #loss_disc = disclosswt*(discfeats)*(2*labels-1)\n            #print(loss_disc)\n            transformedX2X = self.forwardX2X(X1)\n            transformedY2Y = self.forwardY2Y(X2)\n            transformedCycleX2X = self.forwardY2X(transformedX2Y)\n            transformedCycleY2Y = self.forwardX2Y(transformedY2X)\n            \n            loss_reconstruction = self.reconstruction_loss(X1,transformedX2X) + self.reconstruction_loss(X2,transformedY2Y)\n            #loss_cycle = self.reconstruction_loss(X1,transformedCycleX2X) + self.reconstruction_loss(X2,transformedCycleY2Y)\n            #Comment out the line below\n            loss_cycle = self.reconstruction_loss(X1,transformedX2Y) + self.reconstruction_loss(X2,transformedY2X)\n            #loss_classification = self.classification_loss()\n            \n            loss_gen = loss_reconstruction-loss_disc + 0*loss_cycle\n            \n        grads_gen = tape.gradient(loss_gen,self.genTrainableVariables)\n        grads_disc = tape.gradient(loss_disc,self.discTrainableVariables)\n        grads_and_vars_disc = zip(grads_disc, self.discTrainableVariables)\n        \n        #tf.clip_by_value(self.discTrainableVariables,-0.01,0.01)\n        optimizerDisc.apply_gradients(grads_and_vars_disc)\n        grads_and_vars_gen = zip(grads_gen, self.genTrainableVariables)\n        optimizerGen.apply_gradients(grads_and_vars_gen)\n        del tape\n        #print(grads_and_vars_gen)\n        return loss_reconstruction,loss_cycle,loss_disc,discfeats\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def read_and_decode(filename, epochs,size):\n#     filename_queue = tf.train.string_input_producer([filename],num_epochs=epochs)\n\n#     reader = tf.TFRecordReader()\n#     _, serialized_example = reader.read(filename_queue)\n#     features = tf.parse_single_example(serialized_example,\n#                                        features={\n#                                            'img_raw': tf.FixedLenFeature([], tf.string),\n#                                            'domain': tf.FixedLenFeature([1], tf.float32),\n#                                        })\n#     img = tf.decode_raw(features['img_raw'], tf.float32)\n    \n#     img = tf.reshape(img, [size, size, 3])\n#     img = tf.cast(img, tf.float32)\n#     domain = features['domain']\n#     return img,domain\n    features={'img_raw': tf.io.FixedLenFeature([], tf.string)}                                           \n    def _parse_image_function(example_proto):\n        # Parse the input tf.Example proto using the dictionary above.\n        feat = tf.io.parse_single_example(example_proto, features)\n        img = tf.io.decode_raw(feat['img_raw'],tf.float32)       \n        img = tf.reshape(img, [size, size, 1])\n        img = tf.cast(img,tf.float32)\n        return tf.math.log(1+img)\n        \n    \n    raw_dataset = tf.data.TFRecordDataset([filename])\n    raw_dataset = raw_dataset.shard(4, 0)\n \n    raw_dataset = raw_dataset.repeat(count=epochs)\n    raw_dataset = raw_dataset.shuffle(16)\n    \n    parsed_image_dataset = raw_dataset.map(_parse_image_function)\n    parsed_image_dataset = parsed_image_dataset.prefetch(buffer_size=10)\n    parsed_image_dataset = parsed_image_dataset.batch(batch_size=5)\n    return iter(parsed_image_dataset)\n    print(parsed_image_dataset)\n    \n    \n    \n\n\n\n# print(next(imgclassical))\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pickle\nsize=256\ndef train(model,epochs,optimizerGen,optimizerDisc,imgclassical,imgjazz):\n    numbatches = 10\n#     for epoch in range(epochs):\n#     print(next(imgjazz))\n    i=0\n    log = open('log.txt','w')\n    for batch_jazz,batch_class in zip(imgjazz,imgclassical):\n        X = tf.concat((batch_jazz,batch_class),axis=0)\n        Y = tf.expand_dims(tf.concat((tf.ones(batch_jazz.shape[0]),tf.zeros(batch_class.shape[0])),axis=0),-1)\n        Y = 1-Y\n        l1,l2,l3,l4 = model.train_on_batch(X,Y,optimizerGen,optimizerDisc)\n        a = l4.numpy()\n#         b = Y.numpy()\n        print(a[0],a[5])\n#         a = np.where(a>0.5,1.0,0.0)\n#         print(np.sum(a==b))\n        #Make discriminator a Lipschitz func by wt clipping\n        for l in model.discriminator.layers:\n            weights = l.get_weights()\n            weights = [tf.clip_by_value(w, -0.1, 0.1) for w in weights]\n            l.set_weights(weights)        \n        \n        print(i,\"reconstruction-{},cycle-{},disc {} \".format(l1,l2,l3))\n        log.write(\"iteration-{},reconstruction-{},cycle-{},disc {} \\n\".format(i,l1,l2,l3))\n        pickle.dump(model.genTrainableVariables,open(\"GenVars.pkl\",'wb'))\n        pickle.dump(model.discTrainableVariables,open(\"DiscVars.pkl\",'wb'))\n        if i%20 == 0:\n            X1 = batch_jazz\n            Y1 = batch_class\n            Y2 = model.forwardX2Y(X1)\n            X2 = model.forwardY2X(Y1)\n            pickle.dump(Y2,open(\"ClassicalTrans-iter-{}\".format(i),\"wb\"))\n            pickle.dump(X2,open(\"JazzTrans-iter-{}\".format(i),\"wb\"))\n            pickle.dump(Y1,open(\"Classical-iter-{}\".format(i),\"wb\"))\n            pickle.dump(X1,open(\"Jazz-iter-{}\".format(i),\"wb\"))\n            for j in range(len(model.decoders[0].trainable_variables)):\n                print(np.mean(model.decoders[0].trainable_variables[j] - model.decoders[1].trainable_variables[j]))\n            \n\n        i+=1\n\nencs = encoder([size,size,1])\ndecs = [decoder([size,size,1]),decoder([size,size,1])]\nmodel = Model(encs,decs)\noptimizerGen = tf.keras.optimizers.Adam(learning_rate=1e-5)\noptimizerDisc = tf.keras.optimizers.Adam(learning_rate=1e-5)\nimgclassical = read_and_decode(\"../input/styletransfer-revised-256/classical.tfrecords\", epochs=20, size=size)\nimgjazz = read_and_decode(\"../input/styletransfer-revised-256/jazz.tfrecords\", epochs=20, size=size)\n\nmodel.forwardX2Y(next(imgjazz))\nmodel.forwardY2X(next(imgclassical))\nmodel.build_disc(next(imgclassical))\nprint(\"Model Built\")\n# for x in tf.trainable_variables():\n#     if(x.shape==())\n\ntrain(model,10,imgclassical=imgclassical,imgjazz=imgjazz,optimizerGen=optimizerGen,optimizerDisc=optimizerDisc)\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}